<!DOCTYPE html><html><head><meta content="text/html; charset=utf-8" http-equiv="Content-Type" /><meta content="width=device-width, initial-scale=1" name="viewport" /><!--replace-start-0--><!--replace-start-5--><!--replace-start-8--><title>D214 - Data Analytics Graduate Capstone - Nay Naing</title><!--replace-end-8--><!--replace-end-5--><!--replace-end-0--><link href="https://cdn.jsdelivr.net/npm/fomantic-ui@2.8.7/dist/semantic.min.css" rel="stylesheet" /><link href="https://fonts.googleapis.com/css?family=Merriweather|Libre+Franklin|Roboto+Mono&amp;display=swap" rel="stylesheet" /><!--replace-start-1--><!--replace-start-4--><!--replace-start-7--><link href="https://raw.githubusercontent.com/srid/neuron/master/assets/neuron.svg" rel="icon" /><meta content="Nay" name="author" /><meta content="The Data Analytics Graduate Capstone allows students to apply the academic and professional abilities developed as a graduate student. This capstone challenges students to integrate skills and knowledge from several program domains into one project." name="description" /><link href="https://naynaing.tech/D214" rel="canonical" /><meta content="D214 - Data Analytics Graduate Capstone" property="og:title" /><meta content="Nay Naing" property="og:site_name" /><meta content="article" property="og:type" /><meta content="https://naynaing.tech/static/d214/d214_imports.png" property="og:image" /><meta content="D214" property="neuron:zettel-id" /><meta content="D214" property="neuron:zettel-slug" /><meta content="learning" property="neuron:zettel-tag" /><meta content="timeline" property="neuron:zettel-tag" /><meta content="wgu" property="neuron:zettel-tag" /><script type="application/ld+json">[{"@context":"https://schema.org","itemListElement":[{"name":"Nay","item":"https://naynaing.tech","@type":"ListItem","position":1},{"name":"Western Governors University","item":"https://naynaing.tech/WGU","@type":"ListItem","position":2}],"@type":"BreadcrumbList"}]</script><style type="text/css">body{background-color:#eeeeee !important;font-family:"Libre Franklin", serif !important}body .ui.container{font-family:"Libre Franklin", serif !important}body h1, h2, h3, h4, h5, h6, .ui.header, .headerFont{font-family:"Merriweather", sans-serif !important}body code, pre, tt, .monoFont{font-family:"Roboto Mono","SFMono-Regular","Menlo","Monaco","Consolas","Liberation Mono","Courier New", monospace !important}body div.z-index p.info{color:#808080}body div.z-index ul{list-style-type:square;padding-left:1.5em}body div.z-index .uplinks{margin-left:0.29999em}body .zettel-content h1#title-h1{background-color:rgba(27,28,29,0.1)}body nav.bottomPane{background-color:rgba(27,28,29,2.0e-2)}body div#footnotes{border-top-color:#1b1c1d}body p{line-height:150%}body img{max-width:100%}body .deemphasized{font-size:0.94999em}body .deemphasized:hover{opacity:1}body .deemphasized:not(:hover){opacity:0.69999}body .deemphasized:not(:hover) a{color:#808080 !important}body div.container.universe{padding-top:1em}body div.zettel-view ul{padding-left:1.5em;list-style-type:square}body div.zettel-view .pandoc .highlight{background-color:#ffff00}body div.zettel-view .pandoc .ui.disabled.fitted.checkbox{margin-right:0.29999em;vertical-align:middle}body div.zettel-view .zettel-content .metadata{margin-top:1em}body div.zettel-view .zettel-content .metadata div.date{text-align:center;color:#808080}body div.zettel-view .zettel-content h1{padding-top:0.2em;padding-bottom:0.2em;text-align:center}body div.zettel-view .zettel-content h2{border-bottom:solid 1px #4682b4;margin-bottom:0.5em}body div.zettel-view .zettel-content h3{margin:0px 0px 0.4em 0px}body div.zettel-view .zettel-content h4{opacity:0.8}body div.zettel-view .zettel-content div#footnotes{margin-top:4em;border-top-style:groove;border-top-width:2px;font-size:0.9em}body div.zettel-view .zettel-content div#footnotes ol > li > p:only-of-type{display:inline;margin-right:0.5em}body div.zettel-view .zettel-content aside.footnote-inline{width:30%;padding-left:15px;margin-left:15px;float:right;background-color:#d3d3d3}body div.zettel-view .zettel-content .overflows{overflow:auto}body div.zettel-view .zettel-content code{margin:auto auto auto auto;font-size:100%}body div.zettel-view .zettel-content p code, li code, ol code{padding:0.2em 0.2em 0.2em 0.2em;background-color:#f5f2f0}body div.zettel-view .zettel-content pre{overflow:auto}body div.zettel-view .zettel-content dl dt{font-weight:bold}body div.zettel-view .zettel-content blockquote{background-color:#f9f9f9;border-left:solid 10px #cccccc;margin:1.5em 0px 1.5em 0px;padding:0.5em 10px 0.5em 10px}body div.zettel-view .zettel-content.raw{background-color:#dddddd}body .ui.label.zettel-tag{color:#000000}body .ui.label.zettel-tag a{color:#000000}body nav.bottomPane ul.backlinks > li{padding-bottom:0.4em;list-style-type:disc}body nav.bottomPane ul.context-list > li{list-style-type:lower-roman}body .footer-version img{-webkit-filter:grayscale(100%);-moz-filter:grayscale(100%);-ms-filter:grayscale(100%);-o-filter:grayscale(100%);filter:grayscale(100%)}body .footer-version img:hover{-webkit-filter:grayscale(0%);-moz-filter:grayscale(0%);-ms-filter:grayscale(0%);-o-filter:grayscale(0%);filter:grayscale(0%)}body .footer-version, .footer-version a, .footer-version a:visited{color:#808080}body .footer-version a{font-weight:bold}body .footer-version{margin-top:1em !important;font-size:0.69999em}@media only screen and (max-width: 768px){body div#zettel-container{margin-left:0.4em !important;margin-right:0.4em !important}}body span.zettel-link-container span.zettel-link a{color:#1b1c1d;font-weight:bold;text-decoration:none}body span.zettel-link-container span.zettel-link a:hover{background-color:rgba(27,28,29,0.1)}body span.zettel-link-container span.extra{color:auto}body span.zettel-link-container.errors{border:solid 1px #ff0000}body span.zettel-link-container.errors span.zettel-link a:hover{text-decoration:none !important;cursor:not-allowed}body [data-tooltip]:after{font-size:0.69999em}body div.tag-tree div.node{font-weight:bold}body div.tag-tree div.node a.inactive{color:#555555}body .tree.flipped{-webkit-transform:rotate(180deg);-moz-transform:rotate(180deg);-ms-transform:rotate(180deg);-o-transform:rotate(180deg);transform:rotate(180deg)}body .tree{overflow:auto}body .tree ul.root{padding-top:0px;margin-top:0px}body .tree ul{position:relative;padding:1em 0px 0px 0px;white-space:nowrap;margin:0px auto 0px auto;text-align:center}body .tree ul::after{content:"";display:table;clear:both}body .tree ul:last-child{padding-bottom:0.1em}body .tree li{display:inline-block;vertical-align:top;text-align:center;list-style-type:none;position:relative;padding:1em 0.5em 0em 0.5em}body .tree li::before{content:"";position:absolute;top:0px;right:50%;border-top:solid 2px #cccccc;width:50%;height:1.19999em}body .tree li::after{content:"";position:absolute;top:0px;right:50%;border-top:solid 2px #cccccc;width:50%;height:1.19999em}body .tree li::after{right:auto;left:50%;border-left:solid 2px #cccccc}body .tree li:only-child{padding-top:0em}body .tree li:only-child::after{display:none}body .tree li:only-child::before{display:none}body .tree li:first-child::before{border-style:none;border-width:0px}body .tree li:first-child::after{border-radius:5px 0px 0px 0px}body .tree li:last-child::after{border-style:none;border-width:0px}body .tree li:last-child::before{border-right:solid 2px #cccccc;border-radius:0px 5px 0px 0px}body .tree ul ul::before{content:"";position:absolute;top:0px;left:50%;border-left:solid 2px #cccccc;width:0px;height:1.19999em}body .tree li div.forest-link{border:solid 2px #cccccc;padding:0.2em 0.29999em 0.2em 0.29999em;text-decoration:none;display:inline-block;border-radius:5px 5px 5px 5px;color:#333333;position:relative;top:2px}body .tree.flipped li div.forest-link{-webkit-transform:rotate(180deg);-moz-transform:rotate(180deg);-ms-transform:rotate(180deg);-o-transform:rotate(180deg);transform:rotate(180deg)}</style><script async="" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism.min.css" rel="stylesheet" /><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/components/prism-core.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/plugins/autoloader/prism-autoloader.min.js"></script><!--replace-end-7--><!--replace-end-4--><!--replace-end-1--></head><body><div class="ui fluid container universe"><!--replace-start-2--><!--replace-start-3--><!--replace-start-6--><nav class="flipped tree deemphasized" id="zettel-uptree" style="transform-origin: 50%"><ul class="root"><li><ul><li><div class="forest-link"><span class="zettel-link-container"><span class="zettel-link" title="2023-11-08T11:30"><a href="WGU">Western Governors University</a></span></span></div><ul><li><div class="forest-link"><span class="zettel-link-container"><span class="zettel-link"><a href=".">Nay</a></span></span></div></li></ul></li></ul></li></ul></nav><div class="ui text container" id="zettel-container" style="position: relative"><div class="zettel-view"><article class="ui raised attached segment zettel-content"><div class="pandoc"><h1 id="title-h1">D214 - Data Analytics Graduate Capstone</h1><p>The Data Analytics Graduate Capstone allows students to apply the academic and professional abilities developed as a graduate student. This capstone challenges students to integrate skills and knowledge from several program domains into one project.</p><h2 id="course-analysis">Course Analysis</h2><p>This course is structured around three main tasks:</p><h3 id="task-1-capstone-approval-and-release-form">Task 1: Capstone Approval and Release Form</h3><p>The majority of time for this task was revolved around finding a suitable topic for analysis that would be challenging and interesting, while also having a real world use case. I spent maybe several hours alone just looking into various datasets, mostly on Kaggle, downloading several and conducting EDA to attempt to find a dataset that I would like to work with for the entirety of the course. In the end I decided to settle on U.S. Food Imports Data sourced from United States Department of Agriculture. The dataset can be found here <a href="https://catalog.data.gov/dataset/u-s-food-imports">U.S. Food Imports</a>.</p><h3 id="task-2-data-analytics-report-and-executive-suummary">Task 2: Data Analytics Report and Executive Suummary</h3><p>For Task 2, we will define the Research Question and Hypothesis to test for the analysis of the US Foods Imports Data. In this task the following analysis steps will be performed: Data Collection, Data Extraction/Preparation and Exploratory Data Analysis.</p><h4 id="research-question-and-hypothesis">Research Question and Hypothesis</h4><p>Research Question: To what extent can the future import values of specific food commodities such as coffee, teas, and spices into the United States be predicted using time series forecasting models?</p><p>Hypothesis</p><ul><li>Null Hypothesis (H0): The import values of coffee, tea, and spices into the United States for the upcoming year cannot be predicted with an accuracy of 90% using the Mean Absolute Percentage Error (MAPE) as a metric for model performance.“</li><li>Alternative Hypothesis (H1): The import values of coffee, tea, and spices into the United States for the upcoming year can be predicted with an accuracy of 90% or more using the Mean Absolute Percentage Error (MAPE) as a metric for model performance.</li></ul><h4 id="data-collection">Data Collection</h4><p>For this project I titled “Brewing Trends”, I obtained a comprehensive dataset from the United States Department of Agriculture (USDA). This dataset details the import values of various food commodities, including coffee, into the United States over the past 20 years. The data, structured annually, provides insights into the volume and value of food imports and includes key variables such as types of food commodities, year of import, the value of these imports in millions. The primary method of data collection was searching the internet for reliable sources of data such as government data. For this project, I used a dataset provided by the USDA, which can be found on their official website, as well as data.gov.</p><h4 id="data-extractionpreparation">Data Extraction/Preparation</h4><p>Objective of this step will be to extract and prepare the data for use in a time series analysis. Tools and Techniques used is as follows:</p><h5 id="python-anaconda-environment">Python (Anaconda Environment):</h5><ul><li>Usage: Served as the primary programming language for data manipulation and analysis.</li><li>Advantage: Python offers extensive libraries and frameworks that simplify data analysis and model development. Examples include pandas, numpy, matplotlib, and sklearn.</li><li>Disadvantage: Python can be less efficient in terms of execution speed compared to lower-level languages like C++.</li></ul><h5 id="jupyter-notebook-anaconda-environment">Jupyter Notebook (Anaconda Environment):</h5><ul><li>Usage: Jupyter Notebook provided an interactive environment for executing Python code, enabling real-time data manipulation and visualization.</li><li>Advantage: It allows for an interactive coding environment with the ability to visualize data and outputs immediately.</li><li>Disadvantage: Handling very large datasets in Jupyter Notebook can be cumbersome and may lead to performance issues.</li></ul><h5 id="libraries-used">Libraries Used:</h5><ul><li>Pandas: Utilized for data cleaning, manipulation, and analysis. It was instrumental in reformatting the original dataset into a more analyzable format.</li><li>NumPy: Will be used for numerical computations, especially useful in manipulating arrays and performing mathematical operations.</li><li>Matplotlib: Intended for visualizing data, important for understanding data trends and patterns essential for time series forecasting.</li><li>Scikit-learn (Sklearn): To be used for implementing machine learning models, particularly time series forecasting models.</li></ul><h5 id="data-cleaning">Data Cleaning</h5><ul><li>The dataset initially contained irrelevant and misplaced rows and columns.</li><li>Specific rows were identified and selected based on the category they represented (e.g., “Total coffee, tea, and spices”).</li><li>Numeric values were cleaned by removing commas and converting strings to numeric data types.</li><li>Initial imports <img alt="214_Imports" src="./static/d214/d214_imports.png" /></li><li>Load Dataset into Data frame <img alt="214_LoadData" src="./static/d214/d214_load.png" /></li><li>Defining Categories and Headers <img alt="214_DefineCategories" src="./static/d214/d214_define.png" /></li><li>Processing Categories and Appending New Data <img alt="214_ProcessCategories" src="./static/d214/d214_process.png" /></li><li>Cleaning Numeric Values <img alt="214_CleanData" src="./static/d214/d214_numerics.png" /> <img alt="214_CleanData2" src="./static/d214/d214_numerics_display.png" /></li><li>Cleaning Before and After <img alt="214_CleanBefore" src="./static/d214/d214_clean_before.png" /> <img alt="214_CleanAfter" src="./static/d214/d214_clean_after.png" /></li></ul><h4 id="exploratory-data-analysis">Exploratory Data Analysis</h4><h5 id="mean-import-data">Mean Import Data</h5><ul><li>Overall Trend: There is a clear upward trend in the mean import values over the observed period. This suggests an increase in the average value of imports entering the U.S. over time for the commodities being analyzed.</li><li>Periodic Fluctuations: Despite the overall upward trend, there are periods of fluctuation where mean values dip and rise. Notably, there are dips around the early 2000s, mid-2000s, and early 2010s.</li><li>Notable Dips: After a pronounced dip around 2008, which could be attributed to the global financial crisis, there is a significant growth in mean import values peaking around 2011 before another dip.</li><li>Economic Indicators: The exact reasons for the fluctuations and growth could be numerous, including changes in global market demand, price changes of commodities, trade policies, and economic conditions. <img alt="214_MeanImports" src="./static/d214/mean_imports.png" /></li></ul><h5 id="total-imports">Total Imports</h5><ul><li>Overall Trend: The chart shows a general upward trend in total import values over the given time period, indicating an increase in the value of imports.</li><li>Periodic Fluctuations: There are noticeable year-to-year variations in import values, with certain years experiencing significant increases or decreases compared to adjacent years.</li><li>Notable Dips: There are notable dips in the graph, particularly after the years 2000 and 2008, which may correspond to economic downturns, such as the dot-com bubble burst and the global financial crisis.</li><li>Economic Indicators: This upward trajectory, particularly in the latter years, could be influenced by a variety of factors, such as increased demand, inflation, changes in trade policies, or other economic conditions. <img alt="214_TotalImports" src="./static/d214/total_imports.png" /></li></ul><h5 id="imports-by-import-types">Imports by Import Types</h5><ul><li>Overall Trend: The chart generally indicates a rising trend in total import values over the years. This suggests an increase in the U.S. demand for these commodities or a rise in their prices, or both.</li><li>Import Variability: There is variability in the proportional contribution of each category to the total imports. Some categories, such as unroasted coffee beans, show a consistent presence over the years, while others fluctuate more noticeably.</li><li>Notable Increases: There is a pronounced increase in the total import values in the final year, 2022, which is significantly higher than any other year. This could be due to a variety of factors, including market dynamics, changes in trade policies, or economic inflation.</li><li>Economic Indicators: While the overall trend is upward, there are fluctuations from year to year. Some years show a decrease or plateau in total imports, indicating potential economic cycles or changes in industry patterns. <img alt="214_ImportType" src="./static/d214/import_type.png" /></li></ul><h5 id="statistical-analysis-and-modeling">Statistical Analysis and Modeling</h5><ul><li>Aggregate Total Imports by Year: For the time series analysis, I chose to use data aggregated on an annual basis. This data represents the total import values of the specified commodities, chosen because annual aggregation captures the long-term trends and seasonality while filtering out short-term fluctuations. <img alt="214_sa_imports" src="./static/d214/sa_imports.png" /></li><li>Stationarity Check: Using the Augmented Dickey-Fuller (ADF) test, I checked if the time series data is stationary. The data required two rounds of differencing in order to meet the stationarity check requirements. After differencing the data twice, we get an ADF statistic of -6.62 and a very small p-value. As a result, we can confidently reject the null hypothesis that the series has a unit root and conclude that the twice-differenced time series is stationary. <img alt="214_sa_stationarity" src="./static/d214/sa_stationarity.png" /> <img alt="214_sa_stationarity2" src="./static/d214/sa_stationarity2.png" /></li></ul><h5 id="sarima-modeling">SARIMA Modeling</h5><ul><li>Initial SARIMA Model: A SARIMA model was initially fit to the data. However, the Mean Absolute Percentage Error (mape) from this model was high, suggesting that the model was not capturing the underlying data patterns effectively. <img alt="214_sarima_1" src="./static/d214/sarima_1.png" /> <img alt="214_sarima_display" src="./static/d214/sarima_1_display.png" /></li><li>Fine-Tuning SARIMA Parameters: Using the auto_arima function from the pmdarima package, I automated the process of selecting the best-fitting SARIMA model parameters. This tool iteratively explores various combinations of parameters to find the best model based on the lowest AIC or BIC. <img alt="214_sarima_ft" src="./static/d214/sarima_ft.png" /></li><li>Optimized SARIMA Model: The optimized SARIMA model, as suggested by auto_arima, used a combination of non-seasonal and seasonal parameters that were expected to improve the model fit. Despite optimization, the resulting MAPE was still higher than the acceptable threshold, indicating that while the model performance improved, it was not sufficiently accurate for the project’s standards. <img alt="214_sarima_op" src="./static/d214/sarima_optimized.png" /></li></ul><h5 id="prophet-modeling">Prophet Modeling</h5><ul><li>Prophet Model: Due to the SARIMA model not performing as expected, with a higher than acceptable MAPE, the Prophet model was selected for further analysis. Prophet is renowned for its flexibility in managing the seasonality and trend components of a time series, as well as its resilience to missing data and outliers. The dataset was prepared for use with Prophet, which required a DataFrame with two columns: ‘ds’ for the timestamp and ‘y’ for the metric being forecasted. The data was filtered for the relevant years and formatted to meet Prophet’s specifications.</li><li>Initial Prophet Model (1999-2022): The initial model was trained using data spanning from 1999 to 2022. The model was set up with yearly seasonality enabled to capture any annual patterns in the import data. The resulting MAPE was 14.49%, which was above the threshold needed to consider the model highly accurate for the project’s purposes. <img alt="214_prophet" src="./static/d214/prophet_initial.png" /> <img alt="214_prophet_initialplot" src="./static/d214/prophet_initial_plot.png" /></li><li>Refined Prophet Model (2012-2022): Given the high MAPE, a decision was made to refine the analysis by focusing on data from 2012 to 2022. This period was chosen to potentially exclude any anomalous effects from global events that occurred before 2012, which could include the financial crisis of 2008 and other disruptions that may not be representative of future trends. The refined Prophet model provided a MAPE of approximately 8.83%, indicating a better fit and suggesting increased predictive accuracy for this time frame. Confidence intervals were also generated to express the uncertainty in the forecasts. The visualizations included both 80% and 95% confidence intervals, providing a range within which future values are likely to fall. These intervals are crucial for risk assessment and decision-making as they convey the range of possible outcomes and the level of certainty associated with the forecasts. <img alt="214_prophet_refined" src="./static/d214/prophet_refined.png" /> <img alt="214_prophet_refined_plot" src="./static/d214/prophet_refined_plot.png" /></li></ul><h3 id="task-3-executive-summary-and-implications">Task 3: Executive Summary and Implications</h3><p>The executive summary for this project can be found here: <a href="https://github.com/nay244/D214/blob/main/NaingNay_D214_T3.pdf">Executive Summary</a>.</p><hr /></div><div class="metadata"><div class="date" title="Zettel date"><time datetime="2024-05-21T20:25">2024-05-21</time></div></div></article><nav class="ui attached segment deemphasized backlinksPane" id="neuron-backlinks-pane"><h3 class="ui header">Backlinks</h3><ul class="backlinks"><li><span class="zettel-link-container cf"><span class="zettel-link" title="2023-11-07T22:07"><a href="Timeline">Full Timeline</a></span></span><ul class="context-list" style="zoom: 85%;"></ul></li></ul><h3 class="ui header"><span title="Backlinks from folgezettel parents">Uplinks</span></h3><ul class="backlinks"><li><span class="zettel-link-container folge"><span class="zettel-link" title="2023-11-08T11:30"><a href="WGU">Western Governors University</a><span data-nosnippet="" style="user-select: none; color: gray" title="Folgezettel">#</span></span></span><ul class="context-list" style="zoom: 85%;"><li class="item"><div class="pandoc"><span class="zettel-link-container folge"><span class="zettel-link" title="2024-05-21T20:25"><a href="D214">D214 - Data Analytics Graduate Capstone</a><span data-nosnippet="" style="user-select: none; color: gray" title="Folgezettel">#</span></span></span></div></li></ul></li></ul></nav><nav class="ui attached segment deemphasized bottomPane" id="neuron-tags-pane"><div><span class="ui basic label zettel-tag" title="Tag">learning</span><span class="ui basic label zettel-tag" title="Tag">timeline</span><span class="ui basic label zettel-tag" title="Tag">wgu</span></div></nav><nav class="ui bottom attached icon compact inverted menu black" id="neuron-nav-bar"><!--replace-start-9--><a class="item" href="." title="Home"><i class="home icon"></i></a><!--replace-end-9--><a class="item" href="https://github.com/nay244/nay-zettel/edit/master/./D214.md" title="Edit this page"><i class="edit icon"></i></a><a class="right item" href="impulse" title="Open Impulse"><i class="wave square icon"></i></a></nav></div></div><!--replace-end-6--><!--replace-end-3--><!--replace-end-2--><div class="ui center aligned container footer-version"><div class="ui tiny image"><a href="https://neuron.zettel.page"><img alt="logo" src="https://raw.githubusercontent.com/srid/neuron/master/assets/neuron.svg" title="Generated by Neuron 1.9.35.3" /></a></div></div></div></body></html>